// Real-Time Analytics KQL Queries for Email Stream
// These queries run on Fabric Real-Time Analytics (Kusto)

// ==============================================================
// REAL-TIME EMAIL MONITORING
// ==============================================================

// Live email stream - last 1 hour
EmailStream
| where ingestion_timestamp > ago(1h)
| project 
    ingestion_timestamp,
    email_id,
    sender_email,
    subject,
    category,
    priority,
    status
| order by ingestion_timestamp desc
| take 100

// ==============================================================
// LIVE VOLUME METRICS
// ==============================================================

// Real-time email volume by minute
EmailStream
| where ingestion_timestamp > ago(1h)
| summarize 
    email_count = count(),
    unique_senders = dcount(sender_email)
    by bin(ingestion_timestamp, 1m)
| order by ingestion_timestamp desc

// Current hour vs same hour yesterday
let current_hour = EmailStream
    | where ingestion_timestamp > ago(1h)
    | summarize current_count = count();
let yesterday_hour = EmailStream
    | where ingestion_timestamp between (ago(25h) .. ago(24h))
    | summarize yesterday_count = count();
current_hour
| extend yesterday_count = toscalar(yesterday_hour)
| extend percent_change = (current_count - yesterday_count) * 100.0 / yesterday_count
| project current_count, yesterday_count, percent_change

// ==============================================================
// CATEGORY DISTRIBUTION - REAL-TIME
// ==============================================================

// Last hour category breakdown
EmailStream
| where ingestion_timestamp > ago(1h)
| summarize 
    count = count(),
    avg_confidence = avg(category_confidence),
    avg_priority_score = avg(priority_score)
    by category
| extend percentage = count * 100.0 / toscalar(
    EmailStream 
    | where ingestion_timestamp > ago(1h) 
    | count
  )
| order by count desc

// ==============================================================
// SLA MONITORING - CRITICAL
// ==============================================================

// Tickets approaching SLA breach (< 15 minutes remaining)
EmailStream
| where status in ("new", "in_progress")
| where sla_deadline_timestamp > now()
| extend minutes_to_sla = datetime_diff('minute', sla_deadline_timestamp, now())
| where minutes_to_sla < 15
| project 
    ticket_id,
    customer_email,
    subject,
    category,
    priority,
    minutes_to_sla,
    sla_deadline_timestamp,
    assigned_to
| order by minutes_to_sla asc

// SLA breached tickets - requires immediate action
EmailStream
| where status in ("new", "in_progress")
| where sla_deadline_timestamp < now()
| extend minutes_breached = datetime_diff('minute', now(), sla_deadline_timestamp)
| project 
    ticket_id,
    customer_email,
    subject,
    category,
    priority,
    minutes_breached,
    assigned_to,
    received_timestamp
| order by minutes_breached desc

// ==============================================================
// SENTIMENT ANALYSIS - REAL-TIME
// ==============================================================

// Negative sentiment spike detection
EmailStream
| where ingestion_timestamp > ago(15m)
| where sentiment_label == "Negative"
| summarize 
    negative_count = count(),
    avg_sentiment_score = avg(sentiment_score),
    customers = make_set(customer_email, 10)
| extend alert_threshold = 5
| where negative_count > alert_threshold
| project 
    time_window = "Last 15 minutes",
    negative_count,
    avg_sentiment_score,
    sample_customers = customers

// Sentiment trend - last 6 hours
EmailStream
| where ingestion_timestamp > ago(6h)
| summarize 
    avg_sentiment = avg(sentiment_score),
    positive_pct = countif(sentiment_label == "Positive") * 100.0 / count(),
    negative_pct = countif(sentiment_label == "Negative") * 100.0 / count(),
    neutral_pct = countif(sentiment_label == "Neutral") * 100.0 / count()
    by bin(ingestion_timestamp, 30m)
| order by ingestion_timestamp desc

// ==============================================================
// HIGH-VALUE CUSTOMER ALERTS
// ==============================================================

// VIP customer tickets requiring attention
EmailStream
| where customer_tier == "VIP"
| where status in ("new", "in_progress")
| where sentiment_label == "Negative" or priority == "urgent"
| project 
    ticket_id,
    customer_email,
    customer_name,
    subject,
    priority,
    sentiment_label,
    received_timestamp,
    assigned_to
| order by received_timestamp desc

// ==============================================================
// PERFORMANCE METRICS - REAL-TIME
// ==============================================================

// Average response time - rolling 1 hour
EmailStream
| where response_timestamp != datetime(null)
| where response_timestamp > ago(1h)
| extend response_time_minutes = datetime_diff('minute', response_timestamp, received_timestamp)
| summarize 
    avg_response_time = avg(response_time_minutes),
    median_response_time = percentile(response_time_minutes, 50),
    p95_response_time = percentile(response_time_minutes, 95),
    total_responded = count()
    by bin(response_timestamp, 10m)
| order by response_timestamp desc

// Agent workload - current
EmailStream
| where status in ("in_progress")
| where assigned_to != ""
| summarize 
    active_tickets = count(),
    oldest_ticket = min(received_timestamp),
    avg_priority_score = avg(priority_score)
    by assigned_to
| extend minutes_since_oldest = datetime_diff('minute', now(), oldest_ticket)
| order by active_tickets desc

// ==============================================================
// COST TRACKING - REAL-TIME
// ==============================================================

// OpenAI cost - today so far
EmailStream
| where ingestion_timestamp >= startofday(now())
| summarize 
    total_tickets = count(),
    total_cost = sum(openai_cost_usd),
    avg_cost_per_ticket = avg(openai_cost_usd),
    total_tokens = sum(openai_tokens_used)
| extend 
    daily_budget = 800.0 / 30,
    projected_daily_cost = total_cost * (24.0 / todouble(datetime_diff('hour', now(), startofday(now())))),
    budget_utilization_pct = (total_cost / (800.0 / 30)) * 100

// Cost by category - today
EmailStream
| where ingestion_timestamp >= startofday(now())
| summarize 
    ticket_count = count(),
    total_cost = sum(openai_cost_usd),
    avg_cost = avg(openai_cost_usd)
    by category
| order by total_cost desc

// ==============================================================
// ANOMALY DETECTION
// ==============================================================

// Unusual volume spike detection (> 50% increase vs previous hour)
let current = EmailStream
    | where ingestion_timestamp > ago(1h)
    | summarize current_count = count();
let previous = EmailStream
    | where ingestion_timestamp between (ago(2h) .. ago(1h))
    | summarize previous_count = count();
current
| extend previous_count = toscalar(previous)
| extend percent_change = (current_count - previous_count) * 100.0 / previous_count
| where percent_change > 50
| project 
    alert_type = "Volume Spike",
    current_hour_count = current_count,
    previous_hour_count = previous_count,
    percent_increase = percent_change,
    timestamp = now()

// Unusual category distribution (category > 50% of volume)
EmailStream
| where ingestion_timestamp > ago(1h)
| summarize count = count() by category
| extend total = toscalar(EmailStream | where ingestion_timestamp > ago(1h) | count)
| extend percentage = count * 100.0 / total
| where percentage > 50
| project 
    alert_type = "Category Concentration",
    category,
    count,
    percentage,
    timestamp = now()

// ==============================================================
// DASHBOARDS - PRE-AGGREGATED QUERIES
// ==============================================================

// Main dashboard - key metrics
let dashboard_time = now();
let today_start = startofday(dashboard_time);
EmailStream
| where ingestion_timestamp >= today_start
| summarize 
    // Volume
    total_emails = count(),
    new_tickets = countif(status == "new"),
    in_progress = countif(status == "in_progress"),
    resolved = countif(status == "resolved"),
    
    // Performance
    avg_response_time = avgif(datetime_diff('minute', response_timestamp, received_timestamp), response_timestamp != datetime(null)),
    
    // SLA
    sla_met = countif(sla_met == true),
    sla_missed = countif(sla_met == false),
    
    // Sentiment
    negative_sentiment = countif(sentiment_label == "Negative"),
    avg_sentiment = avg(sentiment_score),
    
    // Cost
    total_ai_cost = sum(openai_cost_usd)
| extend 
    resolution_rate = resolved * 100.0 / total_emails,
    sla_compliance = sla_met * 100.0 / (sla_met + sla_missed),
    negative_rate = negative_sentiment * 100.0 / total_emails,
    dashboard_timestamp = dashboard_time
